{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import\n",
                "# Basics\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Vectorize data\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# Data resampling\n",
                "from sklearn.utils import resample\n",
                "\n",
                "# Splitting data\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Coding\n",
                "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
                "\n",
                "# Scaling\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Parameter selection\n",
                "from sklearn.feature_selection import f_regression, pearsonr, mutual_info_regression, SelectKBest\n",
                "\n",
                "# Models\n",
                "# Classification\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# Regression\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.linear_model import Lasso\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from xgboost import XGBRegressor\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "\n",
                "# Model Optmization\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# Metrics\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import precision_score\n",
                "from sklearn.metrics import recall_score\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "# Save the model\n",
                "from pickle import dump"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get data\n",
                "df = pd.read_csv(\"url\")\n",
                "\n",
                "# Configure pandas to display all rows and columns\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "# Initial Data Display\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DataFrame Dimensions\n",
                "df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic Information on Data Types and Non-Null Values\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fill missing values\n",
                "df[\"var1\"] = df[\"var1\"].fillna(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Search and Removal of Duplicate Data\n",
                "duplicates = df.duplicated().sum()\n",
                "\n",
                "# If Necessary\n",
                "df = df.drop_duplicates()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initial Selection of Relevant Features\n",
                "# ..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis of Categorical Variables\n",
                "# If Necessary\n",
                "df[\"feature\"].value_counts()\n",
                "\n",
                "# Graphic analysis\n",
                "fig, axis = plt.subplots(4, 2, figsize = (10, 15))\n",
                "\n",
                "sns.countplot(ax = axis[0, 0], data = df, x = \"var1\", palette='pastel', hue= \"var1\", legend=False)\n",
                "\n",
                "# Rotation\n",
                "axis[0, 0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "sns.countplot(ax = axis[0, 1], data = df, x = \"var2\", palette='pastel', hue= \"var2\", legend=False)\n",
                "\n",
                "sns.countplot(ax = axis[1, 0], data = df, x = \"var3\", palette='pastel', hue= \"var3\", legend=False)\n",
                "\n",
                "sns.countplot(ax = axis[1, 1], data = df, x = \"var4\", palette='pastel', hue= \"var4\", legend=False)\n",
                "\n",
                "# ......\n",
                "\n",
                "# Delete axis\n",
                "axis[3, 1].axis(\"off\")\n",
                "\n",
                "# Horizontal Grid\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "\n",
                "# Adjust the Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Display the Plot\n",
                "plt.show()\n",
                "\n",
                "# Function for Individual Variable Analysis in a Single Plot\n",
                "def graph_feature(feature, rotation=False):\n",
                "    plt.figure(figsize=(4, 4))\n",
                "    ax = sns.countplot(data = df, x = feature, palette='pastel', hue= feature, legend=False)\n",
                "    # Horizontal Grid\n",
                "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "    # Display the Values on Top of Each Bar\n",
                "    for p in ax.patches:\n",
                "        ax.text(p.get_x() + p.get_width() / 2., \n",
                "                p.get_height() + 0.5, \n",
                "                f'{int(p.get_height())}', \n",
                "                ha='center', \n",
                "                va='bottom')\n",
                "    if rotation:\n",
                "        plt.xticks(rotation=45)\n",
                "    # Adjust the Layout\n",
                "    plt.tight_layout()\n",
                "    # Display the Plot\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis of Numerical Variables\n",
                "fig, axis = plt.subplots(6, 2, figsize = (10, 5), gridspec_kw={'height_ratios': [6, 1, 6, 1, 6, 1]})\n",
                "\n",
                "# Set of colors\n",
                "colors = [\n",
                "    \"#FF6F61\", \"#6B5B95\", \"#88B04B\", \"#F7CAC9\", \"#92A8D1\", \"#955251\", \"#B565A7\", \"#009B77\", \"#DD4124\", \"#45B8AC\",\n",
                "    \"#EFC050\", \"#1F3A93\", \"#FF784F\", \"#2E86AB\", \"#A4C639\", \"#D94F70\", \"#7BC8A4\", \"#3F51B5\", \"#F4A261\", \"#66CC99\",\n",
                "    \"#E84A5F\", \"#4682B4\", \"#FFB347\", \"#6A0572\", \"#AB83A1\", \"#FFD1DC\", \"#5DADE2\", \"#A8E6CF\", \"#DC143C\", \"#228B22\",\n",
                "    \"#FF69B4\", \"#4169E1\", \"#FF4500\", \"#20B2AA\", \"#9932CC\", \"#F08080\", \"#00CED1\", \"#ADFF2F\", \"#BA55D3\", \"#87CEEB\",\n",
                "    \"#FF6347\", \"#40E0D0\", \"#C71585\", \"#98FB98\", \"#FFA07A\", \"#00FA9A\", \"#6495ED\", \"#FF8C00\", \"#90EE90\", \"#DB7093\"\n",
                "]\n",
                "\n",
                "# Create a multiple figure with histograms and box plots\n",
                "sns.histplot(ax = axis[0, 0], data = df, x = \"var1\", bins=50, color=\"#1f77b4\").set(xlabel = None)\n",
                "sns.boxplot(ax = axis[1, 0], data = df, x = \"var1\", color=\"#1f77b4\").set(xlabel = \"var1\")\n",
                "\n",
                "sns.histplot(ax = axis[0, 1], data = df, x = \"var2\", bins=50, color=\"#ff7f0e\").set(xlabel = None)\n",
                "sns.boxplot(ax = axis[1, 1], data = df, x = \"var2\", color=\"#ff7f0e\").set(xlabel = \"var2\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 0], data = df, x = \"var3\", bins=50, color=\"#2ca02c\").set(xlabel = None)\n",
                "sns.boxplot(ax = axis[3, 0], data = df, x = \"var3\", color=\"#2ca02c\").set(xlabel = \"var3\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 1], data = df, x = \"var4\", bins=50, color=\"#d62728\").set(xlabel = None)\n",
                "sns.boxplot(ax = axis[3, 1], data = df, x = \"var4\", color=\"#d62728\").set(xlabel = \"var4\")\n",
                "\n",
                "# ......\n",
                "\n",
                "# Delete axis\n",
                "axis[3, 1].axis(\"off\")\n",
                "\n",
                "# Adjust the Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Display the Plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Numerical - Numerical Analysis, Seeking Correlations Between Specific Variables in My Dataset\n",
                "fig, axis = plt.subplots(10, 2, figsize = (12, 17))\n",
                "\n",
                "# Create a Multiple Scatter Plot\n",
                "sns.regplot(ax = axis[0, 0], data = df, x = \"var1\", y = \"target\")\n",
                "sns.heatmap(df[[\"taget\", \"var1\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 0], cbar = False)\n",
                "\n",
                "sns.regplot(ax = axis[0, 1], data = df, x = \"var2\", y = \"target\").set(ylabel=None)\n",
                "sns.heatmap(df[[\"target\", \"var2\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 1])\n",
                "\n",
                "sns.regplot(ax = axis[2, 0], data = df, x = \"var3\", y = \"target\")\n",
                "sns.heatmap(df[[\"target\", \"var3\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 0], cbar = False)\n",
                "\n",
                "sns.regplot(ax = axis[2, 1], data = df, x = \"var4\", y = \"target\").set(ylabel=None)\n",
                "sns.heatmap(df[[\"target\", \"var4\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 1])\n",
                "\n",
                "# ......\n",
                "\n",
                "# Delete axis\n",
                "axis[3, 1].axis(\"off\")\n",
                "\n",
                "# Adjust the Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Display the Plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Categorical - Categorical Analysis\n",
                "fig, axis = plt.subplots(4, 2, figsize = (10, 15))\n",
                "\n",
                "sns.countplot(ax = axis[0, 0], data = df, x = \"var1\", palette='husl', hue= \"target\", legend=True)\n",
                "\n",
                "# Rotation\n",
                "axis[0, 0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "sns.countplot(ax = axis[0, 1], data = df, x = \"var2\", palette='husl', hue= \"target\", legend=True)\n",
                "\n",
                "sns.countplot(ax = axis[1, 0], data = df, x = \"var3\", palette='husl', hue= \"target\", legend=True)\n",
                "\n",
                "sns.countplot(ax = axis[1, 1], data = df, x = \"var4\", palette='husl', hue= \"target\", legend=True)\n",
                "\n",
                "# ......\n",
                "\n",
                "# Delete axis\n",
                "axis[3, 1].axis(\"off\")\n",
                "\n",
                "# Adjust the Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Display the Plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Complete Numerical - Categorical Analysis\n",
                "\n",
                "# Convert, if necessary, categorical variables to numerical ones, in a simple way using pd.factorize()\n",
                "df[\"var1_num\"] = pd.factorize(df[\"var1\"])[0]\n",
                "\n",
                "# Convert a numeric column with erroneous values to numeric\n",
                "df[\"var1\"] = pd.to_numeric(df[\"var1\"], errors=\"coerce\")\n",
                "# Check the data type after the conversion\n",
                "df[\"var1\"].dtype\n",
                "# Check if the conversion generated missing values\n",
                "df[\"var1\"].isnull().sum()\n",
                "\n",
                "fig, axis = plt.subplots(figsize = (15, 10))\n",
                "\n",
                "sns.heatmap(df[[\"var1_num\", \"var2\", \"var3_num\", \"var4\", \"...\"]].corr(), annot = True, fmt = \".2f\")\n",
                "\n",
                "# Adjust the Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Display the Plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# All-to-All Relationships\n",
                "sns.pairplot(data = df)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final exploration of missing values\n",
                "df.isnull().sum().sort_values(ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleaning outliers\n",
                "\n",
                "# Interquartile range\n",
                "var1_info = df[\"var1\"].describe()\n",
                "var1_iqr = var1_info[\"75%\"] - var1_info[\"25%\"]\n",
                "up_limit = var1_info[\"75%\"] + 1.5 * var1_iqr\n",
                "low_limit = var1_info[\"25%\"] - 1.5 * var1_iqr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resampling example\n",
                "# Split the dataset into subsets based on labels\n",
                "label_0 = df[df['var1'] == 0]\n",
                "label_1 = df[df['var1'] == 1]\n",
                "label_2 = df[df['var1'] == 2]\n",
                "\n",
                "# Determine the maximum size to balance\n",
                "max_size = max(len(label_0), len(label_1), len(label_2))\n",
                "\n",
                "# Augmenting underrepresented labels with synthetic data\n",
                "label_0_balanced = resample(label_0, replace=True, n_samples=max_size, random_state=42)\n",
                "label_1_balanced = resample(label_1, replace=True, n_samples=max_size, random_state=42)\n",
                "label_2_balanced = resample(label_2, replace=True, n_samples=max_size, random_state=42)\n",
                "\n",
                "# Combining balanced datasets\n",
                "df = pd.concat([label_0_balanced, label_1_balanced, label_2_balanced])\n",
                "\n",
                "# Mix the rows to avoid any order\n",
                "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "\n",
                "# Check the balance\n",
                "print(df['va1'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Splitting data into train and test sets\n",
                "X = df.drop(\"target\", axis = 1)\n",
                "y = df[\"target\"]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # stratify=y for imbalanced classes in the target\n",
                "\n",
                "\n",
                "# Save my information in two .csv files for work from app.py\n",
                "# Join X_train with y_train\n",
                "train_data = pd.concat([X_train, y_train], axis=1)\n",
                "\n",
                "# Join X_test with y_test\n",
                "test_data = pd.concat([X_test, y_test], axis=1)\n",
                "\n",
                "# Save to CSV files\n",
                "train_data.to_csv('../data/processed/train_data.csv', index=False)\n",
                "test_data.to_csv('../data/processed/test_data.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorize data if necessary\n",
                "\n",
                "# Function to clean text\n",
                "def clean_text(texto):\n",
                "    texto = texto.lower() # Lower case\n",
                "    texto = re.sub(r'\\d+', '', texto) # Numbers\n",
                "    texto = re.sub(r'[^\\w\\s]', '', texto) # Punctuation marks\n",
                "    texto = re.sub(r'\\s+', ' ', texto).strip() # Multiple spaces and at the beginning and end\n",
                "    return texto\n",
                "\n",
                "# Clean up text in column \"var1\"\n",
                "df[\"var1\"] = df[\"var1\"].apply(clean_text)\n",
                "\n",
                "# Vectorization with TfidfVectorizer\n",
                "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
                "\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train[\"review\"])\n",
                "X_test_tfidf = vectorizer.transform(X_test[\"review\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Coding\n",
                "\n",
                "# With Label Encoder\n",
                "# Instantiate the encoder\n",
                "label_encoder_var1 = LabelEncoder()\n",
                "# Train the encoder with the training data\n",
                "label_encoder_var1.fit(X_train['var1'])\n",
                "# Apply the encoder on both\n",
                "X_train['var1_le'] = label_encoder_var1.transform(X_train['var1'])\n",
                "X_test['var1_le'] = label_encoder_var1.transform(X_test['var1'])\n",
                "# After checking the coding, remove the uncoded feature\n",
                "X_train = X_train.drop(\"var1\", axis=1)\n",
                "X_test = X_test.drop(\"var1\", axis=1)\n",
                "\n",
                "# With Ordinal Encoder\n",
                "# Instantiate the encoder with the order of the categories\n",
                "ordinal_encoder_var1 = OrdinalEncoder(categories=[[\"cat1\", \"cat2\", \"cat3\"]])\n",
                "# Train the encoder with the training data\n",
                "ordinal_encoder_var1.fit(X_train['var1'])\n",
                "# Apply the encoder on both\n",
                "X_train['var1_oe'] = ordinal_encoder_var1.transform(X_train['var1'])\n",
                "X_test['var1_oe'] = ordinal_encoder_var1.transform(X_test['var1'])\n",
                "# After checking the coding, remove the uncoded feature\n",
                "X_train = X_train.drop(\"var1\", axis=1)\n",
                "X_test = X_test.drop(\"var1\", axis=1)\n",
                "\n",
                "# Alternative with pd.factorize() or pd.get_dummies()\n",
                "df[\"var1_num\"] = pd.factorize(df[\"var1\"])[0]\n",
                "df = pd.get_dummies(df, columns=[\"var1\", \"var2\", \"var3\"])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scaling\n",
                "# Instantiate the scaler\n",
                "scaler = StandardScaler().fit(X_train) # or MinMaxScaler\n",
                "# Transformation and conversion to dataframe of scaled data\n",
                "X_train_scaled = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
                "X_test_scaled = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Selecting the best parameters for the model\n",
                "selection_model = SelectKBest(mutual_info_regression, k = 5).fit(X_train_scaled, y_train) # f_regression, pearsonr, mutual_info_regression\n",
                "\n",
                "# Train the model\n",
                "selection_model.fit(X_train_scaled, y_train)\n",
                "ix = selection_model.get_support()\n",
                "\n",
                "# Apply the model\n",
                "X_train_sel = pd.DataFrame(selection_model.transform(X_train_scaled), columns = X_train_scaled.columns.values[ix])\n",
                "X_test_sel = pd.DataFrame(selection_model.transform(X_test_scaled), columns = X_test_scaled.columns.values[ix])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ML Models\n",
                "model = RandomForestClassifier(random_state = 42)\n",
                "# Training\n",
                "model.fit(X_train_sel, y_train)\n",
                "# Predict\n",
                "y_pred_test = model.predict(X_test_sel)\n",
                "y_pred_train = model.predict(X_train_sel)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Metrics\n",
                "# Classification\n",
                "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
                "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
                "f1_score_test = f1_score(y_test, y_pred_test)\n",
                "f1_score_train = f1_score(y_train, y_pred_train)\n",
                "precision_test = precision_score(y_test, y_pred_test)\n",
                "precision_train = precision_score(y_train, y_pred_train)\n",
                "recall_test = recall_score(y_test, y_pred_test)\n",
                "recall_train = recall_score(y_train, y_pred_train)\n",
                "\n",
                "print(\"Accuracy Test: \", accuracy_test)\n",
                "print(\"F1 score Test: \", f1_score_test)\n",
                "print(\"Precision Test: \", precision_test)\n",
                "print(\"Recall Test: \", recall_test)\n",
                "\n",
                "print(\"Accuracy Train: \", accuracy_train)\n",
                "print(\"F1 score Train: \", f1_score_train)\n",
                "print(\"Precision Train: \", precision_train)\n",
                "print(\"Recall Train: \", recall_train)\n",
                "\n",
                "# Create the confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred_test)\n",
                "\n",
                "# Graph the confusion matrix\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.xlabel('Predicción')\n",
                "plt.ylabel('Verdadero')\n",
                "plt.title('Matriz de Confusión')\n",
                "plt.show()\n",
                "\n",
                "# --------------------------------------------------\n",
                "\n",
                "# Regression\n",
                "mse_test = mean_squared_error(y_test, y_pred_test)\n",
                "r2_score_test = r2_score(y_test, y_pred_test)\n",
                "rmse_test = np.sqrt(mse_test)\n",
                "mse_train = mean_squared_error(y_train, y_pred_train)\n",
                "r2_score_train = r2_score(y_train, y_pred_train)\n",
                "rmse_train = np.sqrt(mse_train)\n",
                "\n",
                "print(\"MSE Test: \", mse_test)\n",
                "print(\"R2 Score Test: \",r2_score_test)\n",
                "print(\"RMSE Test: \", rmse_test)\n",
                "\n",
                "print(\"MSE Train: \", mse_train)\n",
                "print(\"R2 Score Train: \",r2_score_train)\n",
                "print(\"RMSE Train: \", rmse_train)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
